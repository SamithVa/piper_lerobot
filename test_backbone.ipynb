{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1965729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wanshan/miniconda3/envs/lerobot/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/data/wanshan/miniconda3/envs/lerobot/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/data/wanshan/miniconda3/envs/lerobot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 128, 32, 32])\n",
      "torch.Size([1, 256, 16, 16])\n",
      "torch.Size([1, 512, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "\n",
    "img = Image.open('./image.png')\n",
    "\n",
    "model = timm.create_model(\n",
    "    'fastvit_sa12.apple_in1k',\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 64, 64, 64])\n",
    "    #  torch.Size([1, 128, 32, 32])\n",
    "    #  torch.Size([1, 256, 16, 16])\n",
    "    #  torch.Size([1, 512, 8, 8])\n",
    "\n",
    "    print(o.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e4044fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastVit normalization:\n",
      "  Mean: (0.485, 0.456, 0.406)\n",
      "  Std: (0.229, 0.224, 0.225)\n",
      "\n",
      "Standard ImageNet normalization:\n",
      "  Mean: (0.485, 0.456, 0.406)\n",
      "  Std: (0.229, 0.224, 0.225)\n",
      "\n",
      "Are they the same? True\n"
     ]
    }
   ],
   "source": [
    "# Check FastVit's normalization requirements\n",
    "import timm\n",
    "\n",
    "model = timm.create_model(\n",
    "    'fastvit_sa12.apple_in1k',\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "print(\"FastVit normalization:\")\n",
    "print(f\"  Mean: {data_config['mean']}\")\n",
    "print(f\"  Std: {data_config['std']}\")\n",
    "\n",
    "# Compare with standard ImageNet normalization\n",
    "print(\"\\nStandard ImageNet normalization:\")\n",
    "print(f\"  Mean: (0.485, 0.456, 0.406)\")\n",
    "print(f\"  Std: (0.229, 0.224, 0.225)\")\n",
    "\n",
    "print(\"\\nAre they the same?\", data_config['mean'] == (0.485, 0.456, 0.406) and data_config['std'] == (0.229, 0.224, 0.225))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5deb745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature info for all layers:\n",
      "  Layer 0: 64 channels (module: stages.0)\n",
      "  Layer 1: 128 channels (module: stages.1)\n",
      "  Layer 2: 256 channels (module: stages.2)\n",
      "  Layer 3: 512 channels (module: stages.3)\n",
      "\n",
      "Last layer channels (what ACT will use): 512\n"
     ]
    }
   ],
   "source": [
    "# Check what backbone_feature_dim would be\n",
    "import timm\n",
    "\n",
    "model = timm.create_model(\n",
    "    'fastvit_sa12.apple_in1k',\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "\n",
    "print(\"Feature info for all layers:\")\n",
    "for i, info in enumerate(model.feature_info):\n",
    "    print(f\"  Layer {i}: {info['num_chs']} channels (module: {info['module']})\")\n",
    "\n",
    "print(f\"\\nLast layer channels (what ACT will use): {model.feature_info[-1]['num_chs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ea9886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wanshan/miniconda3/envs/lerobot/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/wanshan/miniconda3/envs/lerobot/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SPATIAL RESOLUTION COMPARISON (This is why you run out of VRAM!)\n",
      "============================================================\n",
      "ResNet18 output shape:  torch.Size([1, 512, 7, 7])\n",
      "FastVit output shape:   torch.Size([1, 512, 7, 7])\n",
      "\n",
      "ResNet18 tokens per image:  49\n",
      "FastVit tokens per image:   49\n",
      "\n",
      "FastVit has 1.0x MORE tokens!\n",
      "Attention memory scales with O(n²), so ~1.0x more VRAM!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# CRITICAL: Compare spatial resolutions (this is the VRAM killer!)\n",
    "import torch\n",
    "import torchvision\n",
    "import timm\n",
    "\n",
    "# Simulate your dataset's image size\n",
    "img_size = (224, 224)  # Change to your actual image size\n",
    "dummy_input = torch.randn(1, 3, *img_size)\n",
    "\n",
    "# ResNet18\n",
    "resnet = torchvision.models.resnet18(pretrained=False)\n",
    "from torchvision.models._utils import IntermediateLayerGetter\n",
    "resnet_backbone = IntermediateLayerGetter(resnet, return_layers={\"layer4\": \"feature_map\"})\n",
    "resnet_out = resnet_backbone(dummy_input)[\"feature_map\"]\n",
    "\n",
    "# FastVit\n",
    "fastvit = timm.create_model('fastvit_sa12.apple_in1k', pretrained=False, features_only=True)\n",
    "fastvit_out = fastvit(dummy_input)[-1]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SPATIAL RESOLUTION COMPARISON (This is why you run out of VRAM!)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ResNet18 output shape:  {resnet_out.shape}\")\n",
    "print(f\"FastVit output shape:   {fastvit_out.shape}\")\n",
    "print()\n",
    "print(f\"ResNet18 tokens per image:  {resnet_out.shape[2] * resnet_out.shape[3]}\")\n",
    "print(f\"FastVit tokens per image:   {fastvit_out.shape[2] * fastvit_out.shape[3]}\")\n",
    "print()\n",
    "ratio = (fastvit_out.shape[2] * fastvit_out.shape[3]) / (resnet_out.shape[2] * resnet_out.shape[3])\n",
    "print(f\"FastVit has {ratio:.1f}x MORE tokens!\")\n",
    "print(f\"Attention memory scales with O(n²), so ~{ratio**2:.1f}x more VRAM!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d44ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapped extractor output keys: dict_keys(['feature_map'])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# test custom wrapper\n",
    "class TimmFeatureExtractorWrapper(nn.Module):\n",
    "    \"\"\"Wrapper for timm models to match IntermediateLayerGetter's return format.\"\"\"\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # timm features_only models return a list of feature maps\n",
    "        # With out_indices=[-1], we only get the last feature map\n",
    "        features = self.model(x)\n",
    "        return {\"feature_map\": features[0] if len(features) == 1 else features[-1]}\n",
    "    \n",
    "\n",
    "image_feature_extractor = timm.create_model(\n",
    "    'fastvit_sa12.apple_in1k',\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "wrapped_extractor = TimmFeatureExtractorWrapper(image_feature_extractor)\n",
    "wrapped_extractor.eval()\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "output = wrapped_extractor(dummy_input)\n",
    "print(\"Wrapped extractor output keys:\", output.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6edbf",
   "metadata": {},
   "source": [
    "## Tesing `Shuffle Net`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25af3699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleNetV2(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (stage2): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(464, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# suffle net\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "# intermediate layer getter\n",
    "from torchvision.models._utils import IntermediateLayerGetter\n",
    "\n",
    "weights = torchvision.models.ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1\n",
    "model = torchvision.models.shufflenet_v2_x1_0(weights=weights)\n",
    "backbone = IntermediateLayerGetter(model, return_layers={\"stage4\": \"feature_map\"})\n",
    "\n",
    "image = Image.open('./image.png')\n",
    "# preprocess\n",
    "preprocess = weights.transforms()\n",
    "input_tensor = preprocess(image).unsqueeze(0)  # create a mini-batch as\n",
    "input_batch = input_tensor  # single image batch\n",
    "# inference\n",
    "with torch.no_grad():\n",
    "    output = backbone(input_batch)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b8e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dim: 464\n"
     ]
    }
   ],
   "source": [
    "backbone_feature_dim = model.conv5[0].in_channels\n",
    "print(\"Backbone feature dim:\", backbone_feature_dim)\n",
    "# using conv1d for \n",
    "input_proj = nn.Conv2d(\n",
    "                backbone_feature_dim, 512, kernel_size=1\n",
    "            )\n",
    "input_proj_output = input_proj(output[\"feature_map\"])\n",
    "print(\"Input projection output shape:\", input_proj_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c591af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dino \n",
    "import timm \n",
    "\n",
    "backbone_model = timm.create_model(\n",
    "                'vit_small_patch16_224.dino',\n",
    "                pretrained=True,\n",
    "                features_only=True,\n",
    "                out_indices=[-1],  # Only extract last layer to avoid memory leak\n",
    "            )\n",
    "backbone_feature_dim = backbone_model.feature_info[-1]['num_chs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c0dcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_feature_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996a61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
